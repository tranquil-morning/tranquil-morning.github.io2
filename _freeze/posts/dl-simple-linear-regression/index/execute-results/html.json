{
  "hash": "1e03e6d8d866a6ebe7b15957db9b3618",
  "result": {
    "markdown": "---\ntitle: \"딥러닝을 위한 Simple Linear Regression\"\nauthor: \"Jinwook Chang\"\ndate: \"2023-05-04\"\ndate-modified: \"2023-05-04\"\ncategories: [DataScience, Regression, DeepLearning, Script]\n---\n\n\n하기와 같이 공부한 시간과 성적의 데이터가 있을 때, 시간을 통해 성적를 예측하고자 합니다. 두 변수의 관계가 선형적이라 가정할 때, 하기의 파란색 선과 같이 점수를 가장 잘 예측하는 선을 찾는 것이 이번 포스트의 목적입니다.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 2\n  hours score\n  <dbl> <dbl>\n1    10    90\n2     9    80\n3     3    50\n4     2    30\n```\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/plot1-1.png){width=672}\n:::\n:::\n\n\n위의 선을 다음과 같은 식으로 표기하도록 해봅시다.\n\n$$ H(x) = Wx + b $$ 이 선과 실제 데이터의 오차는 하기와 같이 표기할 수 있습니다.\n\n$$ cost(W,b) = \\frac{1}{m}\\sum_{i=1}^{m}(H(x^{(i)}) - y^{(i)})^2 $$\n\n여기서 우리의 목적은 cost(오차)를 최소화 할 수 있는 W,b의 쌍을 찾는 것입니다. 오차를 최소화 하는 값을 찾기 위해, Gradient Descent를 통해 확인해보도록 하겠습니다.\n\n1.  초기 값 W,b에 대한 각각의 편미분 값을 구합니다.\n2.  편미분 값에 learning rate $\\alpha$를 곱해줍니다.\n3.  W, b에 곱해준 값을 뺀 후 W, b 값을 업데이트 합니다.\n4.  cost가 만족할만한 수준이 될 때 까지 1 \\~ 3을 반복합니다.\n\n$$ W := W - \\alpha\\frac{\\partial}{\\partial W}cost(W,b) $$ $$ b := b - \\alpha\\frac{\\partial}{\\partial b}cost(W,b) $$ 예시 데이터를 아래의 스크립트를 통해 $Wx + b$를 구해보도록 하겠습니다.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 필요한 라이브러리 불러오기\nlibrary(tidyverse)\nlibrary(glue)\n\n# Gradient Descent 함수 정의\ngradient_descent_simple_lr <- function(X, y, alpha = 0.005, iterations = 3000) {\n  m <- length(X)\n  b <- runif(1) # 절편 초기화\n  w <- runif(1) # 가중치 초기화\n  \n  for (i in 1:iterations) {\n    y_hat <- w * X + b\n    error <- y - y_hat\n    b_gradient <- sum(error) * (-2 / m)\n    w_gradient <- sum(error * X) * (-2 / m)\n    b <- b - alpha * b_gradient\n    w <- w - alpha * w_gradient\n  }\n  \n  return(list(\"b\" = b, \"W\" = w))\n}\n\n# Gradient Descent 실행\nresult <- gradient_descent_simple_lr(example$hours, example$score)\n\n# 결과 출력\n\ncat(glue(\"절편 : {result$b} \\n가중치 : {result$W}\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n절편 : 22.8894921206597 \n가중치 : 6.60130678294047\n```\n:::\n\n```{.r .cell-code}\nmod <- lm(score ~ hours, example)\ncat(mod$coefficients)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n22.9 6.6\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}